---
title: 'Denoising Diffusion Probabilistic Models'
date: 2024-03-23
permalink: /posts/diffusion/
tags:
  - tutorial
  - deep learning
  - machine learning
  - probabilistic models
---


_THIS POST IS CURRENTLY UNDER CONSTRUCTION_

Introduction
------------

In a [previous post](https://mbernste.github.io/posts/vae/), we walked through the theory and implementation of the variational autoencoder, which is a probabilistic generative model that uses variational inference combined with neural networks to model and sample from complex distributions. In this post, we will walk through another such model: the **denoising diffusion probabilistic model**. Specifically, we will walk through the model presented by [Ho, Jain, Abbeel, (2020)](https://arxiv.org/pdf/2006.11239.pdf).

At the time of this writing, diffusion models are state-of-the-art models used for image generation and have achieved what are, in my opinion, breathtaking results in generating incredibly detailed, realistic images. Below, is an example image generated by [DALLÂ·E 3](https://openai.com/dall-e-3) (via [ChatGPT](https://openai.com/gpt-4)), which as far as I understand, uses diffusion models as part of their image generation machinery.

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/dalle3_example.png" alt="drawing" width="500"/></center>

<br>

Diffusion models are also being explored in biomedical research. For example, the [Chroma](https://www.nature.com/articles/s41586-023-06728-8) model, developed by [Generate: Biomedicines](https://generatebiomedicines.com/), uses diffusion as part of their method for generating novel, functional protein sequences. 

Because of these models' incredible performance, I was curious to understand they work. While I have a relatively good understanding into the theory behind the variational autoencoder, diffusion models presented a bigger challenge as the mathematics is more involved. In this post, I will step through an explanation into the theory behind diffusion models. We will start by presenting a high-level overview of how diffusion models work. We will then derive the learning and sampling algorithms from first principles. We will then compare and contrast this model with the more familiar variational autoencoder. Lastly, we will implement a simple diffusion model in [PyTorch](https://pytorch.org/) and apply it to the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) of hand-written digits.

High-level overview of denoising diffusion models
-------------------------------------------------

Like all probabilistic generative models, diffusion models can be understood as a probability distribution over some set of objects of interest. These objects might be images, text documents, or protein sequences. Let $boldsymbol{x}$ be a vector representing one such object. Then, diffusion models can be understood as a probability distribution $p(\boldsymbol{x})$. Once we have this distribution in hand, we can sample objects from this distribution. In the case of image generation, we can view the process of generating an image as _sampling_ from a distribution:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_sampling_images.png" alt="drawing" width="800"/></center>

<br>

For diffusion models, the exact form of $p(\boldsymbol{x})$ is actually never explicitly defined; rather, $p(\boldsymbol{x})$ emerges through an attempt at reversing a [diffusion process](https://en.wikipedia.org/wiki/Diffusion_process). Reversing a diffusion process? What does that mean? Let's dig in.

First, given a vector $\boldsymbol{x}$ representing an object (e.g., an image), we will define a diffuction process in which we iteratively add Gaussian noise to $\boldsymbol{x}$ over a series of $T$ timesteps. Let's let $\boldsymbol{x}_t$ be $\boldsymbol{x}$ at time step $t$. Note that $\boldsymbol{x}_0$ represents the original object before noise was added to it. If $\boldsymbol{x}$ is an image of my dog Korra, this diffusion process would look like the following:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_korra_forward.png" alt="drawing" width="800"/></center>

The central goal of a diffusion model is to learn how to reverse this diffusion process -- that is, to remove the noise at each time step:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_korra_forward.png" alt="drawing" width="800"/></center>






Theoretical derivation of the learning and sampling algorithms
--------------------------------------------------------------

Let $x_t \sim N(\mu, 1)$ and $x_{t+1} \sim N(a x_t, \beta_1)$. Then 

Diffusion models as hierarchical variational autoencoders
---------------------------------------------------------



Applying a diffusion model on MNIST
-----------------------------------


Appendix
--------
