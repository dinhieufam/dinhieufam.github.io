---
title: 'Denoising Diffusion Probabilistic Models'
date: 2024-03-23
permalink: /posts/diffusion/
tags:
  - tutorial
  - deep learning
  - machine learning
  - probabilistic models
---


_THIS POST IS CURRENTLY UNDER CONSTRUCTION_

Introduction
------------

In a [previous post](https://mbernste.github.io/posts/vae/), we walked through the theory and implementation of the variational autoencoder, which is a probabilistic generative model that combines variational inference and neural networks to model and sample from complex distributions. In this post, we will walk through another such model: the **denoising diffusion probabilistic model**. Specifically, we will walk through the model presented by [Ho, Jain, and Abbeel (2020)](https://arxiv.org/pdf/2006.11239.pdf).

At the time of this writing, diffusion models are state-of-the-art models used for image generation and have achieved what are, in my opinion, breathtaking results in generating incredibly detailed, realistic images. Below, is an example image generated by [DALLÂ·E 3](https://openai.com/dall-e-3) (via [OpenAI](https://openai.com/)'s [ChatGPT](https://openai.com/gpt-4)), which as far as I understand, uses diffusion models as part of their image generation machinery.

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/dalle3_example.png" alt="drawing" width="500"/></center>

<br>

Diffusion models are also being explored in biomedical research. For example, the [Chroma](https://www.nature.com/articles/s41586-023-06728-8) model, developed by [Generate: Biomedicines](https://generatebiomedicines.com/), uses diffusion as part of their method for generating novel, functional protein sequences. 

Because of these models' incredible performance in image generation, and their burgeoning use-cases in computational biology, I was curious to understand how they work. While I have a relatively good understanding into the theory behind the variational autoencoder, diffusion models presented a bigger challenge as the mathematics is more involved. In this post, I will step through an explanation into the theory behind diffusion models. We will start by presenting a high-level overview of how diffusion models work. We will then derive the learning and sampling algorithms from first principles. We will then compare and contrast this model with the more familiar variational autoencoder. Lastly, we will implement a simple diffusion model in [PyTorch](https://pytorch.org/) and apply it to the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) of hand-written digits.

Much of my understanding of this material came from the following resources:
* [These lecture notes](https://www.davidinouye.com/course/ece57000-fall-2022/lectures/diffusion-models.pdf) by David I. Inouye
* [This blog post](https://paramhanji.github.io/posts/2021/06/ddpm/) by Param Hanji
* [This blog post](https://angusturner.github.io/generative_models/2021/06/29/diffusion-probabilistic-models-I.html) by Angus Turner
* [This lecture](https://www.youtube.com/watch?v=687zEGODmHA&t=1212s&ab_channel=MachineLearningatBerkeley) at UC, Berkeley

High-level overview of denoising diffusion models
-------------------------------------------------

Like all probabilistic generative models, diffusion models can be understood as a probability distribution over some set of objects of interest. These objects might be images, text documents, or protein sequences. Let $\boldsymbol{x}$ be a vector representing one such object. Then, diffusion models can be understood as a probability distribution $p(\boldsymbol{x})$. Once we have this distribution in hand, we can sample objects from this distribution. In the case of image generation, we can view the process of generating an image as _sampling_ from a distribution:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_sampling_images.png" alt="drawing" width="800"/></center>

<br>

For diffusion models, the exact form of $p(\boldsymbol{x})$ is actually never explicitly defined; rather, $p(\boldsymbol{x})$ emerges through an attempt at reversing a [diffusion process](https://en.wikipedia.org/wiki/Diffusion_process). Reversing a diffusion process? What does that mean? Let's dig in.

First, given a vector $\boldsymbol{x}$ representing an object (e.g., an image), we will define a diffuction process in which we iteratively add Gaussian noise to $\boldsymbol{x}$ over a series of $T$ timesteps. Let's let $\boldsymbol{x}_t$ be $\boldsymbol{x}$ at time step $t$. Note that $\boldsymbol{x}_0$ represents the original object before noise was added to it. If $\boldsymbol{x}$ is an image of my dog Korra, this diffusion process would look like the following:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_korra_forward.png" alt="drawing" width="800"/></center>

The central goal of a diffusion model is to learn how to reverse this diffusion process -- that is, to remove the noise at each time step:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_korra_forward_reverse.png" alt="drawing" width="800"/></center>

More specifically, for each step, $t$, in the forward diffusion process, we will add noise by sampling the next object $\boldsymbol{x}\_{t+1}$ from a Gaussian that is centered near $\boldsymbol{x}\_{t}$. (Note, we will rigorously this distribution in the next section. For now, one can just think of the process of sampling from this distribution as adding noise to $\boldsymbol{x}\_t$).  That is,

$$\boldsymbol{x}_{t+1} \sim q(\boldsymbol{x}_{t+1} \mid \boldsymbol{x}_t)$$

To remove the noise, we can sample from the posterior distribution, $q(\boldsymbol{x}\_t \mid \boldsymbol{x}\_{t+1})$. One idea to derive this distribution would be to use [Bayes Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem):

$$q(\boldsymbol{x}_t \mid \boldsymbol{x}_{t+1}) = \frac{q(\boldsymbol{x}_{t+1} \mid \boldsymbol{x}_t)q(\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_t)}$$

This process of removing noise by iteratively sampling from the posteriors is depicted below:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_korra_forward_reverse_distributions_exact.png" alt="drawing" width="800"/></center>

Unfortunately, as is the case in many scenarios where one wishes to apply Bayes Theorem, the exact form of this posterior is intractable to compute. That is because, for any timestep $t$, in order to compute $q(\boldsymbol{x}_t)$, we have to marginalize over all of the time steps prior to $t$:

$$\begin{align*} q(\boldsymbol{x}_t) &= \int_{\boldsymbol{x}_{t-1},\dots,\boldsymbol{x}_0} q(\boldsymbol{x}_t \mid \boldsymbol{x}_{t-1}, \dots, \boldsymbol{x}_0) \ d\boldsymbol{x}_{t-1}\dots \boldsymbol{x}_{0} \\ &= \int_{\boldsymbol{x}_{t-1},\dots,\boldsymbol{x}_0} q(\boldsymbol{x}_0)\prod_{i=1}^{t} q(\boldsymbol{x}_i \mid \boldsymbol{x}_{i-1}) \ d\boldsymbol{x}_{t-1}\dots \boldsymbol{x}_{0} \end{align*}$$

This marginalization requires that we define a distribution $q(\boldsymbol{x}_0)$, which is a distribution over noiseless objects (e.g., a distribution over noiseless images). Unfortunately, we don't know what this is -- that is our whole purpose of developing a diffusion model! As it will turn out, we will not ever need to define $q(\boldsymbol{x}_0)$.

Now, as we do in [variational inference](https://mbernste.github.io/posts/variational_inference/), we will instead _approximate_ $q(\boldsymbol{x}\_t \mid \boldsymbol{x}\_{t+1})$ with a surrogate distribution $p_{\theta}(\boldsymbol{x}\_t \mid \boldsymbol{x}\_{t+1})$ where $\theta$ are learnable parameters that will be used to fit the distribution as close to $q(\boldsymbol{x}\_t \mid \boldsymbol{x}\_{t+1})$ as possible. As we will see in the next section, $p_{\theta}(\boldsymbol{x}\_t \mid \boldsymbol{x}\_{t+1})$ can incorporate a neural network so that it can be quite a complex distribution. 

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_korra_forward_reverse_distributions_approximate.png" alt="drawing" width="800"/></center>

<br>

Thus, our central task will be to learn each $p_{\theta}(\boldsymbol{x}\_t \mid \boldsymbol{x}\_{t+1})$ distribution from a set of training data. Once, we have these distributions in hand, we can generate an object by first sampling white noise $\boldsymbol{x}\_T$ from a standard normal distribution $N(\boldsymbol{0}, \boldsymbol{I})$, and then iteratively sample $\boldsymbol{x}\_{t-1}$ from each learned $p\_{\theta}(\boldsymbol{x}\_{t-1} \mid \boldsymbol{x}\_{t})$ distribution. At the end of this process we will have "transformed" the random white noise into an object!

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/diffusion_example_generation_frog.png" alt="drawing" width="800"/></center>

<br>

Note that the marginal distribution $p_{\theta}(\boldsymbol{x})$ defined by the diffusion model would be the marginal distribution over all of the intermediate, noisy versions $\boldsymbol{x}$. That is, if we let $\boldsymbol{x}_0 := \boldsymbol{x}$ (i.e., we assume that $\boldsymbol{x}$ is end result of reversing a diffusion process), then 

$$\begin{align*}p_{\theta}(\boldsymbol{x}) = \int_{\boldsymbol{x}_0, \dots, \boldsymbol{x}_T} p(\boldsymbol{x}_T) \prod_{t=1}^T p(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}) \end{align*}$$

In the next sections, we will more rigorously define the distributions $q(\boldsymbol{x}\_{t+1} \mid \boldsymbol{x}\_t}$ 

and $p_\theta(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t}$. We will then derive the learning algorithm, based on [variational inference](https://mbernste.github.io/posts/variational_inference/), for fitting finding $\theta$ such that we will approximate the posteriors $q(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t}$ via each $p_\theta(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t}$ while simultaneously maximizing the marginal distribution $p_{\theta}(\boldsymbol{x})$ of our training data. 


The forward model
-----------------

At each timestep $t$, we seek to add Gaussian noise to $\boldsymbol{x}\_t$ in order to produce $\boldsymbol{x}\_{t+1}$. Specifically, for some $\beta \in [0,1]$, we produce $\boldsymbol{x}\_{t+1}$ from $\boldsymbol{x}\_t$ via:

$$\begin{align*}\epsilon &\sim N(0, 1) \\ \boldsymbol{x}_{t+1} &:= \sqrt{1-\beta}\boldsymbol{x}_t + \beta\epsilon \end{align*}$$

That is, we sample noise, $\epsilon$, from a standard normal distribution, multiply it by a variance term $\beta$, and then add it to a scaled version of $\boldsymbol{x}\_t$. This is the equivalent of sampleing $\boldsymbol{x}\_{t+1}$ from

$$\boldsymbol{x}_{t+1} \sim N\left(\sqrt{1-\beta}\boldsymbol{x}_t, \beta \boldsymbol{I}\right)$$

where $N\left(\sqrt{1-\beta}\boldsymbol{x}_t, \beta \boldsymbol{I}\right)$ is a normal distribution with mean $\sqrt{1-\beta}\boldsymbol{x}_t$ and covariance matrix $\beta \boldsymbol{I}$. Note that $\beta \boldsymbol{I}$ is a diagonal matrix, and thus the noise is independent across each each dimension. 

Thus, we see that $q(\boldsymbol{x}_{t+1} \mid \boldsymbol{x}_t)$ is defined as

$$q(\boldsymbol{x}_{t+1} \mid \boldsymbol{x}_t) \:= N\left(\boldsymbol{x}_{t+1}; \sqrt{1-\beta}\boldsymbol{x}_t, \beta \boldsymbol{I}\right)$$

Here $N\left(\boldsymbol{x}_{t+1}; \sqrt{1-\beta}\boldsymbol{x}_t, \beta \boldsymbol{I}\right)$ represents the normal density function over $\boldsymbol{x}_{t+1}$ with mean $\sqrt{1-\beta}\boldsymbol{x}_t$ and covariance matrix $\beta \boldsymbol{I}$.

### Variance schedules

Note, that $\beta$ determines the amount of variance that is added at each timestep. This may be constant across all timesteps, or one may choose a **variance schedule** such that each timestep, $t$, has a unique variance $\beta_t$. 

### The scaling term 

### Properties of the forward process

The form of the forward, conditional distributions, $q(\boldsymbol{x}_{t+1} \mid \boldsymbol{x}_t)$ admits the following properties that will be convenient to the process of deriving the learning algorithm:

* **$q(\boldsymbol{x}_t \mid \boldsymbol{x}_0)$ has a closed form:** Specifically, we can derive the distribution of the object at any timestep $t$ along the forward process conditioned on the noiseless, original object $\boldsymbol{x}_0$. That distribution is:

$$q(\boldsymbol{x}_t \mid \boldsymbol{x}_0) := $$

See Derivation 1 in the Appendix to this blog post. Said differently, this derivation means that we can generate an object at _any_ timestep $t$ along the diffusion process by sampling from the above distribution. This is depicted schematically below:


* **$q(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0)$ has a closed form:** Previously, showed that the condition distribution, $q(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t)$ was intractible to compute. However, it turns out that if instead of _only_ conditioning on the next timestep, but we also condition on the original, noiseless object, $\boldsymbol{x}_0$, we _can_ derive the conditional distribution. That distribution is:

  


The reverse model
-----------------

Fitting diffusion models via variational inference
--------------------------------------------------



Let $x_t \sim N(\mu, 1)$ and $x_{t+1} \sim N(a x_t, \beta_1)$. Then 

Viewing diffusion models as hierarchical variational autoencoders
-----------------------------------------------------------------



Applying a diffusion model on MNIST
-----------------------------------


Appendix
--------
