---
title: 'Denoising Diffusion Probabilistic Models'
date: 2024-03-23
permalink: /posts/diffusion/
tags:
  - tutorial
  - deep learning
  - machine learning
  - probabilistic models
---


_THIS POST IS CURRENTLY UNDER CONSTRUCTION_

Introduction
------------

In a [previous post](https://mbernste.github.io/posts/vae/), we walked through the theory and implementation of the variational autoencoder, which is a probabilistic generative model that uses variational inference combined with neural networks to model and sample from complex distributions. In this post, we will walk through another such model: the **denoising diffusion model**.

At the time of this writing, denoising diffusion models are state-of-the-art models used for image generation and have achieved what are, in my opinion, breathtaking results in generating incredibly detailed, realistic images. Below, is an example image generated by [DALLÂ·E 3](https://openai.com/dall-e-3), which as far as I understand, uses diffusion models as part of their model.

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/dalle3_example.png" alt="drawing" width="700"/></center>





Because of their incredible performance, I was curious to understand how these models work. While I understood the variational autoencoder, and was able to write a blog post on the topic walking through their theory, diffusion models presented a bigger challenge to understand them as the mathematics is a bit more involved. In this 

Let $x_t \sim N(\mu, 1)$ and $x_{t+1} \sim N(a x_t, \beta_1)$. Then 
