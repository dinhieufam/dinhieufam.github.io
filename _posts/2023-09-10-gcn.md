---
title: 'Graph convolutional neural networks'
date: 2023-09-10
permalink: /posts/gcn/
tags:
  - tutorial
  - deep learning
  - machine learning
---

_This post is currently under construction_ 

Introduction
------------

Graphs are ubiqitous mathematical objects that describe a set of relationships between entities; however, they are challenging to model with traditional machine learning methods, which require that the input be represented as a tensor. Graphs break this paradigm due to the fact that the order of edges and nodes are arbitrary -- that is, they are _permutation invariant_ -- and the model must be capable of accomodating this feature.  In this post, we will discuss graph convolutional networks (GCNs) as presented by [Kipf and Welling (2016)](https://arxiv.org/abs/1609.02907): a class of neural network designed to operate on graphs. As their name suggestions, graph convolutional neural networks can be understood as performing a convolution in the same way that traditional convolutional neural networks (CNNs) are performing a convolution-like operation (i.e., [cross correlation](https://en.wikipedia.org/wiki/Cross-correlation)) when operating on image data. This analogy is depicted below:

<br>

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_vs_CNN_overview.png" alt="drawing" width="500"/></center>

In this post, we will discuss the intution behind the GCN and how it is similar and different to the CNN. We will conclude by presenting a case-study training a GCN to classify molecule toxicity. 

Inputs and outputs of a GCN
---------------------------

Fundamentally, a GCN takes as input a graph together with a set of [feature vectors](https://en.wikipedia.org/wiki/Feature_(machine_learning)) where each node is associated with its own feature vector. The GCN is then composed of a series of graph convolutional layers (to be discussed in the next section) that iteratively transform the feature vectors at each node. The output is then the graph associated with output vectors associated with each node. These output vectors can be (and often are) of different dimension than the input vectors. This is depicted below:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_output_vectors_per_node.png" alt="drawing" width="800"/></center>

If the task at hand is a "node-level" task, such as performing [classification](https://en.wikipedia.org/wiki/Statistical_classification) on the nodes, then these per-node vectors would be treated as the model's final outputs. In the example case of node-level classification, these output vectors could encode the probabilities that each node is associated with each class. 

Alternatively, we may be interested in performing a "graph-level" task, where instead of building a model that produces an output per node, we are interested in task that requires an output over the graph as a whole. For example, we may be interested in classifying whole graphs rather than individual nodes. In this scenario, the per-node vectors could be fed, collectively, into another neural network (such as a simple [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron)), that operates on all them to produce a single output vector. This scenario is depicted below:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_output_vectors_per_graph.png" alt="drawing" width="800"/></center>

Note, GCNs can also perform "edge-level" tasks, but we will not discuss this here. See [this article by Sanchez-Lengeling  _et al_. (2021)](https://distill.pub/2021/gnn-intro/) for a discussion on how GCNs can perform various types of tasks with graphs. 

In the next sections we will dig deeper into the graph convolutional layer and discuss how the per-node embeddings can be combined for producing graph-wide output.


The graph convolutional layer
-----------------------------

GCNs are composed of layers of modules called **graph convolutional layers** in a similar way that traditional CNNs are composed of convolutional layers. Each convolutional layer takes as input each node's vector from the previous layer (in the case of the first layer this would be the input feature vectors) and produces a corresponding output vector for each node. To do so, the graph convolutional layer pools the vectors from each node's neighbors as depicted below:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_conv_layer_message_pass_1.png" alt="drawing" width="800"/></center>

In the schematic above, node A's vector, denoted $\boldsymbol{x}_A$ is pooled/aggregated with the vectors of its neighbors. This pooled vector is then transformed/updated to form the next layer's vector at node A, denoted $\boldsymbol{h}_A$. This same procedure is carred out over every node. Below we show this same process, but on node D:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_conv_layer_message_pass_2.png" alt="drawing" width="800"/></center>

We can view this process as a similar convolution-like operation that is performed in CNNs on images. That is, we can view this as passing a **filter** (also called a **kernel**) over each node such that when the filter is centered over a given node, it combines data from the nearby nodes to produce the output vector for that node. In the figure below, we show how a filter is moved over a graph in a similar way that a filter is moved over an image in a traditional CNN: 


Now, how exactly does a GCN perform the aggregation and update? To answer this, we'll now dig into the mathematics of a GCN. Let $\boldsymbol{X} \in \mathbb{R}^{n \times d}$ be the features corresponding to the nodes where $n$ is the number of nodes and $d$ is the number of features. That is, row $i$ of $\boldsymbol{X}$ stores the features of node $i$. Then, the network's first layer's embedded vectors, denoted $\boldsymbol{H}_1 \in \mathbb{R}^{n \times d_1}$, where $d_1$ is the number of dimensions in the first embedding, is computed as:

$$\boldsymbol{H}_1 := \sigma\left(\hat{\boldsymbol{D}}^{-1/2}(\boldsymbol{A}+\boldsymbol{I})\hat{\boldsymbol{D}}^{-1/2} \boldsymbol{X}\boldsymbol{W}_1\right)$$

where,

$$\begin{align*}\boldsymbol{A} \in \mathbb{R}^{n \times n} &:= \text{The adjacency matrix} \\ \boldsymbol{I} \in \mathbb{R}^{n \times n} &:= \text{The identity matrix} \\ \hat{\boldsymbol{D}} \in \mathbb{R}^{n \times n} &:= \text{The degree matrix of } \ \boldsymbol{A}+\boldsymbol{I} \\ \boldsymbol{X} \in \mathbb{R}^{n \times d} &:= \text{The input data (i.e., the per-node feature vectors)} \\ \boldsymbol{W}_1 \in \mathbb{R}^{d \times d_1} &:= \text{The neural network's first layer's weights} \\ \sigma(.) &:= \text{The activation function (e.g., ReLU)}\end{align*}$$

When I first saw this equation I found it to be quite confusing. Here is what each matrix multiplication is doing in this function:


The first three matrices are normalizing the adjacency matrix. To simplify the equation, we can let

$$\tilde{\boldsymbol{A}} := \hat{\boldsymbol{D}}^{-1/2}(\boldsymbol{A}+\boldsymbol{I})\hat{\boldsymbol{D}}^{-1/2}$$

Then, the graph convolutional layer function becomes:

$$\boldsymbol{H}_1 := \sigma\left(\tilde{\boldsymbol{A}}\boldsymbol{X}\boldsymbol{W}_1\right)$$


<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_aggregation_matrices.png" alt="drawing" width="700"/></center>

<br>

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_as_neural_net.png" alt="drawing" width="800"/></center>


Related links
-------------

* **A Gentle Introduction to Graph Neural Networks** [https://distill.pub/2021/gnn-intro/](https://distill.pub/2021/gnn-intro/)
* **Graph Convolutional Networks** [https://tkipf.github.io/graph-convolutional-networks/](https://tkipf.github.io/graph-convolutional-networks/)






