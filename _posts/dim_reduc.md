

Introduction
------------

The advancement of technology has brought with it the ability to generate ever larger and more complex collections of data. This is especially true in biomedical research, where new technologies can produce thousands, or even millions, of biomolecular measurements at a time. Because we human beings use our vision as our chief sense for understanding the world, when we are confronted with data, we try to understand that data through visualization. Moreover, because we evolved in a three-dimensional world, we can only ever visualize up to three dimensions of an object at a time. This limitation poses a fundamental problem when it comes to high-dimensional data; high-dimensional data cannot, without loss of information, be visualized in their totality at once. But this does not mean we have not tried! The field of [dimension reduction algorithms](https://en.wikipedia.org/wiki/Dimensionality_reduction#:~:text=Dimensionality%20reduction%2C%20or%20dimension%20reduction,close%20to%20its%20intrinsic%20dimension.) studies and develops algorithms that map high dimensional data to two or three dimensions where we can visualize it with minimal loss of information. For example, the classical [principal components analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) uses a linear mapping to project data down to a space that preserves as much variance as possible. More recently, the [t-SNE](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) and [UMAP](https://arxiv.org/pdf/1802.03426.pdf) algorithms, use a [nonlinear mapping](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction) that attempts to preserve the "topology" of the data -- that is, that attempts to preserve neighborhoods of data points while preventing overlapping dense regions of data in the output figure. A few examples of single-cell RNA-seq data visualized with these three approaches are shown below:



Unfortunately, because it is mathematically impossible to avoid losing information when mapping data from high to low dimensions, these algorithms inevitibly lose some aspect of the data, either by distortion or ommision, when plotting it in lower dimensions. This limitation makes these methods of visualization generate easily misinterpreted figures. Because of this, many dimension reduction algorithms, especially [t-SNE](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) and [UMAP](https://arxiv.org/pdf/1802.03426.pdf), are facing [new scrutiny](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011288) by those who argue that these "non-linear" dimension reduction algorithms distort the data so heavily, that they are both useless and even outright harmful due to their potential to mislead. On the other hand, proponents of these methods argue that distortion is inevitable, but that these methods can and do reveal aspects of the data's structure.

In this blog post, I will attempt to provide my views on the matter that balance the views of the critics and proponents. I will start with a review of what it means to "visualize" data. I will also review what it means to perform dimensionality reduction. Finally, I will argue that dimension reduction methods require a different kind of mentality when using them than traditional data visualizations that do not attempt to compress high dimensional data into few dimensions. For much of this blog, I will use data generated by single-cell [RNA-sequencing](https://mbernste.github.io/posts/rna_seq_basics/) (scRNA-seq) as the primary example of high-dimensional data which I will use in case study of the risks and merits of dimension reduction. For a comprehensive review on RNA-seq, please see [my previous blog post](https://mbernste.github.io/posts/rna_seq_basics/). 

Data visualization: mapping numbers to sizes, distances, and colors
-------------------------------------------------------------------

Dimensionality reduction entails a loss of information
------------------------------------------------------

Inferences are the primary product of a data visualization
----------------------------------------------------------

A probabistic framework for thinking about inferences generated by data visualizations
--------------------------------------------------------------------------------------




